# Copyright 2021, 2022, 2023 LuoJiaNET Research and Development Group, Wuhan University
# Copyright 2021, 2022, 2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unlesee you know exactly what you are doing)
enable_modelarts: False
# url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# path for local
data_path: "./data"
output_path: "./train"
load_path: ""
#device_target: "Ascend"
device_target: "CPU"
enable_profiling: False
need_modelarts_dataset_unzip: False
modelarts_dataset_unzip_name: "MindRecord_COCO"

# ======================================================================================
# common options
distribute: False

# ======================================================================================
# create dataset
create_dataset: "facemask"
prefix: "retinanet.mindrecord"
is_training: True
python_multiprocessing: False

# ======================================================================================
# Training options
img_shape: [600,600]
num_retinanet_boxes: 67995
match_thershold: 0.5
nms_thershold: 0.6
min_score: 0.1
max_boxes: 100

# learning rate settings
lr: 0.002
global_step: 0
lr_init: 1e-5
lr_end_rate: 5e-4
lr_scheduler: "cosine_annealing"
lr_epochs: "220,250"
lr_gamma: 0.1
eta_min: 0.0
T_max: 320         # please set 320 when run on 1p
max_epoch: 320       # please set 320 when run on 1p
warmup_epochs: 20  # please set 4 when run on 1p
warmup_epochs1: 0
warmup_epochs2: 1
warmup_epochs3: 4
warmup_epochs4: 12
warmup_epochs5: 30
momentum: 0.9
weight_decay: 1.5e-4

# network
num_default: [9, 9, 9, 9, 9]
extras_out_channels: [256, 256, 256, 256, 256]
feature_size: [75, 38, 19, 10, 5]
aspect_ratios: [[0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0]]
steps: [8, 16, 32, 64, 128]
anchor_size: [32, 64, 128, 256, 512]
prior_scaling: [0.1, 0.2]
gamma: 2.0
alpha: 0.75
num_classes: 11

# `mindrecord_dir` and `coco_root` are better to use absolute path.
mindrecord_dir: "/data02/tjy/NWPU/NWPU_Retinanet_TRAIN"
dataset_root: "/data02/tjy/NWPU"
train_data_type: "train2017"
val_data_type: "val2017"
instances_set: "annotations/instances_{}.json"
coco_classes: ["background",'airplane', 'ship', 'storage tank', 'baseball diamond', 'tennis court',
'basketball court', 'ground track field', 'harbor', 'bridge', 'vehicle']


# The annotation.json position of voc validation dataset
voc_root: "/data02/tjy/NWPU"
facemask_root: "/data02/tjy/NWPU"

# voc original dataset
voc_dir: "/data02/tjy/NWPU"
facemask_dir: "/data02/tjy/NWPU"

# if coco or voc used, `image_dir` and `anno_path` are useless
image_dir: ""
anno_path: ""
save_checkpoint: True
save_checkpoint_epochs: 1
keep_checkpoint_max: 10
save_checkpoint_path: "./ckpt"
finish_epoch: 0

# optimiter options
workers: 8
mode: "sink"
epoch_size: 95
batch_size: 4
pre_trained: "/data02/tjy/RetinaNet/ckpt/retinanet_2-5_113.ckpt"
pre_trained_epoch_size: 90
loss_scale: 200
filter_weight: True
finetune: True

# ======================================================================================
# Eval options
dataset: "facemask"
checkpoint_path: "/data02/tjy/RetinaNet/ckpt/retinanet-2_113.ckpt"

# ======================================================================================
# export options
device_id: 0
file_format: "MINDIR"
export_batch_size: 1
file_name: "retinanet"

# ======================================================================================
# postprocess options
result_path: ""
img_path: ""
img_id_file: ""

---
# Help description for each configuration
enable_modelarts: "Whether training on modelarts default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of input data"
output_pah: "The location of the output file"
device_target: "device id of GPU or Ascend. (Default: None)"
enable_profiling: "Whether enable profiling while training default: False"
workers: "Num parallel workers."
lr: "Learning rate, default is 0.1."
mode: "Run sink mode or not, default is sink."
epoch_size: "Epoch size, default is 500."
batch_size: "Batch size, default is 32."
pre_trained: "Pretrained Checkpoint file path."
pre_trained_epoch_size: "Pretrained epoch size."
save_checkpoint_epochs: "Save checkpoint epochs, default is 1."
loss_scale: "Loss scale, default is 1024."
filter_weight: "Filter weight parameters, default is False."
dataset: "Dataset, default is coco."
device_id: "Device id, default is 0."
file_format: "file format choices [AIR, MINDIR]"
file_name: "output file name."
export_batch_size: "batch size"
result_path: "result file path."
img_path: "image file path."
img_id_file: "image id file."
