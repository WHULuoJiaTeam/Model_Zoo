# Copyright 2021, 2022, 2023 LuoJiaNET Research and Development Group, Wuhan University
# Copyright 2021, 2022, 2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unlesee you know exactly what you are doing)
enable_modelarts: False
# url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "GPU"
enable_profiling: False
need_modelarts_dataset_unzip: True
modelarts_dataset_unzip_name: "MindRecord_COCO"

# ======================================================================================
# common options
distribute: False

# ======================================================================================
# create dataset
create_dataset: "coco"
prefix: "retinanet_eval.mindrecord"
is_training: False

# ======================================================================================
# Training options
img_shape: [600, 600]
num_retinanet_boxes: 67995
match_thershold: 0.5
nms_thershold: 0.8
min_score: 0.1
max_boxes: 100
device_num: 1

# learning rate settings
lr: 0.002
lr_scheduler: "cosine_annealing"
lr_epochs: "220,250"
lr_gamma: 0.1
eta_min: 0.0
T_max: 320         # please set 320 when run on 1p
max_epoch: 320       # please set 320 when run on 1p
warmup_epochs: 20  # please set 4 when run on 1p
#lr_init: 1e-6
#lr_end_rate: 5e-3
#warmup_epochs1: 2
#warmup_epochs2: 5
#warmup_epochs3: 23
#warmup_epochs4: 60
#warmup_epochs5: 160
momentum: 0.9
weight_decay: 1.5e-4

# network
num_default: [9, 9, 9, 9, 9]
extras_out_channels: [256, 256, 256, 256, 256]
feature_size: [75, 38, 19, 10, 5]
aspect_ratios: [[0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0], [0.5, 1.0, 2.0]]
steps: [8, 16, 32, 64, 128]
anchor_size: [32, 64, 128, 256, 512]
prior_scaling: [0.1, 0.2]
gamma: 2.0
alpha: 0.75
num_classes: 11

# `mindrecord_dir` and `coco_root` are better to use absolute path.
mindrecord_dir: "/data02/tjy/NWPU/NWPU_Retinanet_EVAL"
coco_root: "/media/xx/新加卷/DATA/NWPU/"
train_data_type: "train2017"
val_data_type: "val2017"
instances_set: "annotations/instances_{}.json"
coco_classes: ["background",'airplane', 'ship', 'storage tank', 'baseball diamond', 'tennis court',
'basketball court', 'ground track field', 'harbor', 'bridge', 'vehicle']

#coco_classes: ["background", "person", "bicycle", "car", "motorcycle", "airplane", "bus",
#                     "train", "truck", "boat", "traffic light", "fire hydrant",
#                     "stop sign", "parking meter", "bench", "bird", "cat", "dog",
#                     "horse", "sheep", "cow", "elephant", "bear", "zebra",
#                     "giraffe", "backpack", "umbrella", "handbag", "tie",
#                     "suitcase", "frisbee", "skis", "snowboard", "sports ball",
#                     "kite", "baseball bat", "baseball glove", "skateboard",
#                     "surfboard", "tennis racket", "bottle", "wine glass", "cup",
#                     "fork", "knife", "spoon", "bowl", "banana", "apple",
#                     "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza",
#                     "donut", "cake", "chair", "couch", "potted plant", "bed",
#                     "dining table", "toilet", "tv", "laptop", "mouse", "remote",
#                     "keyboard", "cell phone", "microwave", "oven", "toaster", "sink",
#                     "refrigerator", "book", "clock", "vase", "scissors",
#                     "teddy bear", "hair drier", "toothbrush"]

# The annotation.json position of voc validation dataset
voc_root: "/data02/tjy/NWPU"

# voc original dataset
voc_dir: ""

# if coco or voc used, `image_dir` and `anno_path` are useless
image_dir: ""
anno_path: ""
save_checkpoint: True
save_checkpoint_epochs: 1
keep_checkpoint_max: 350
save_checkpoint_path: "/data02/tjy/OUTPUT/RetinaNet/test3/train"
finish_epoch: 0

# optimiter options
workers: 8
mode: "sink"
epoch_size: 3
batch_size: 32
pre_trained: "/data02/tjy/RetinaNet/ckpt/retinanet_2-5_113.ckpt"
pre_trained_epoch_size: 100
loss_scale: 1024.0
filter_weight: False

# ======================================================================================
# Eval options
dataset: "coco"
checkpoint_path: "/data02/tjy/RetinaNet/ckpt/retinanet_3-240_113.ckpt"


# ======================================================================================
# Infer options
infer_log: "/home/xx/Desktop/RetinaNet/infer_result"
rank: 0

# ======================================================================================
# Onnx eval options
dataset: "coco"
onnx_path: "./retinanet.onnx"

# ======================================================================================
# export options
device_id: 0
file_format: "MINDIR"
export_batch_size: 1
file_name: "retinanet"

# ======================================================================================
# postprocess options
result_path: ""
img_path: ""
img_id_file: ""

---
# Help description for each configuration
enable_modelarts: "Whether training on modelarts default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of input data"
output_pah: "The location of the output file"
device_target: "device id of GPU or Ascend. (Default: None)"
enable_profiling: "Whether enable profiling while training default: False"
workers: "Num parallel workers."
lr: "Learning rate, default is 0.1."
mode: "Run sink mode or not, default is sink."
epoch_size: "Epoch size, default is 500."
batch_size: "Batch size, default is 32."
pre_trained: "Pretrained Checkpoint file path."
pre_trained_epoch_size: "Pretrained epoch size."
save_checkpoint_epochs: "Save checkpoint epochs, default is 1."
loss_scale: "Loss scale, default is 1024."
filter_weight: "Filter weight parameters, default is False."
dataset: "Dataset, default is coco."
device_id: "Device id, default is 0."
file_format: "file format choices [AIR, MINDIR]"
file_name: "output file name."
export_batch_size: "batch size"
result_path: "result file path."
img_path: "image file path."
img_id_file: "image id file."
